{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81023720",
   "metadata": {},
   "source": [
    "### moving from jinja to python.py prompts \n",
    "i though i will use jinja for prompts here but forget that  jinja is not made for routing , my prompts \n",
    "here looks less like template and more like dynamic routing prompts \n",
    "\n",
    " i was using lots and lots of if else condition \n",
    "say for 20 agent , checking 20 if else condition make system slow so i am moving \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abefb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"    \n",
    "    Returns the prompt text for a given role and agent type.\n",
    "    Fills in any required variables provided as kwargs.\n",
    "    \n",
    "    Parameters:\n",
    "        role (str): 'system' or 'user'\n",
    "        agent_type (str): e.g., 'validator_agent', 'researcher_agent'\n",
    "        **kwargs: required variables for the prompt (if any)\n",
    "        \n",
    "    Returns:\n",
    "        str: Fully rendered prompt text\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from prompt import get_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fed6f",
   "metadata": {},
   "source": [
    "## create an MCP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b20a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_1\n",
      "Hello, this is a test message.\n",
      "{'priority': 'high', 'parents': ['writer-agent'], 'task_id': '70658341-83ef-4a4d-8fab-066c27ddbc5c'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "from pydantic import BaseModel , field_validator , Field \n",
    "from typing import Dict, Any , Union , TypedDict\n",
    "import uuid\n",
    "\n",
    "\n",
    "class ValidatorContext(BaseModel):\n",
    "    task: str\n",
    "    source_summary: str\n",
    "    draft_post: str\n",
    "\n",
    "\n",
    "\n",
    "class MCPMessage(BaseModel):\n",
    "    protocol_version: str = \"1.0\"\n",
    "    sender: str= Field(min_length=3)\n",
    "    content: Any\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "def create_mcp_message(sender: str ,  content: Any, metadata=None) -> MCPMessage:\n",
    "    \"\"\"Create a message in MCP format.\"\"\"\n",
    "\n",
    "    \n",
    "    if not isinstance(content, (str, dict, ValidatorContext)):\n",
    "        raise TypeError(\n",
    "            f\"content must be str, dict, or ValidatorContext; got {type(content).__name__}\"\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    metadata = metadata or {} \n",
    "    metadata.setdefault(\"task_id\", str(uuid.uuid4()))\n",
    "    metadata.setdefault(\"parents\",[])\n",
    "\n",
    "    return MCPMessage(\n",
    "        sender=sender,\n",
    "        content=content,\n",
    "        metadata=metadata   \n",
    "    )\n",
    "\n",
    "mcp_answer = create_mcp_message(\"agent_1\", \"Hello, this is a test message.\", {\"priority\": \"high\" , \"parents\": [\"writer-agent\"]})\n",
    "print(mcp_answer.sender)\n",
    "print(mcp_answer.content)\n",
    "print(mcp_answer.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a8b57",
   "metadata": {},
   "source": [
    "####  not using any fallback logics or anything or simplicity \n",
    "#### i found i  will only use those if topic specific or  in end to end projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc8274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_context_librarian(mcp_message):\n",
    "    \"\"\"\n",
    "        Retrieves the appropriate Semantic Blueprint from the Context Library.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------- type check --------------------\n",
    "    if not isinstance(mcp_message, dict):\n",
    "        raise TypeError(\"mcp_message must be a dictionary\")\n",
    "\n",
    "    # --- structure check ---\n",
    "    if \"content\" not in mcp_message or not isinstance(mcp_message[\"content\"], dict):\n",
    "        raise KeyError(\"mcp_message must contain a 'content' dictionary\")\n",
    "\n",
    "    if \"intent_query\" not in mcp_message[\"content\"]:\n",
    "        raise KeyError(\"mcp_message['content'] must contain 'intent_query'\")\n",
    "\n",
    "    if not isinstance(mcp_message[\"content\"][\"intent_query\"], str):\n",
    "        raise TypeError(\"'intent_query' must be a string\")\n",
    "\n",
    "        \n",
    "    print(\"\\\\n[Librarian] Activated. Analyzing intent...\")\n",
    "    requested_intent = mcp_message['content']['intent_query']\n",
    "    results = query_pinecone(requested_intent, NAMESPACE_CONTEXT, top_k=1)\n",
    "    if results:\n",
    "        match = results[0]\n",
    "        print(f\"[Librarian] Found blueprint '{match['id']}' (Score:{match['score']:.2f})\")\n",
    "        blueprint_json = match['metadata']['blueprint_json']\n",
    "        content = {\"blueprint\": blueprint_json}\n",
    "\n",
    "    else:\n",
    "        print(\"[Librarian] No specific blueprint found. Returning default.\")\n",
    "        content = {\"blueprint\": json.dumps({\"instruction\": \"Generate the content neutrally.\"})}\n",
    "    return create_mcp_message(\"Librarian\", content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef9009",
   "metadata": {},
   "source": [
    "## research agent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb6569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'genai-mas-mcp-ch3'\n",
    "NAMESPACE_KNOWLEDGE = \"KnowledgeStore\"\n",
    "NAMESPACE_CONTEXT = \"ContextLibrary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753121c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pine cone query \n",
    "from helper import query_pinecone \n",
    "## takes  query_text , namespaces and tok k (optional, because defult is 1)\n",
    "## and return index query ... response['matches']\n",
    "\n",
    "query_pinecone(topic = \"writer agent\")\n",
    "\n",
    "results = query_pinecone(topic, NAMESPACE_KNOWLEDGE, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81026aec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'genai-mas-mcp-ch3' already exists.\n"
     ]
    }
   ],
   "source": [
    "def get_or_create_index(\n",
    "    pc,\n",
    "    index_name: str,\n",
    "    embedding_dim: int,\n",
    "    namespaces_to_clear: List[str] | None = None,\n",
    "    metric: str = \"cosine\",\n",
    "    cloud: str = \"aws\",\n",
    "    region: str = \"us-east-1\",\n",
    "    delete_timeout_seconds: int = 120,\n",
    "    poll_interval: int = 2,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0766b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_or_create_index' from 'helper' (/home/ujjwal/projects/Context-Enginnering/helper.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_or_create_index\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'get_or_create_index' from 'helper' (/home/ujjwal/projects/Context-Enginnering/helper.py)"
     ]
    }
   ],
   "source": [
    "from helper import get_or_create_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f7445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: this this\\n\\nSources:\\nthsihs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompt import get_prompt\n",
    "get_prompt(role= \"user\" , \n",
    "           agent_type=\"research_synthesis_ai\",\n",
    "           topic = \"this this\" ,\n",
    "\n",
    "           sources=\"thsihs\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = query_pinecone(topic, NAMESPACE_KNOWLEDGE, top_k=3)\n",
    "\n",
    "\n",
    "source_texts = [match['metadata']['text'] for match in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1282a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9a8e9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_pinecone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mquery_pinecone\u001b[49m(topic, NAMESPACE_KNOWLEDGE, top_k=\u001b[32m3\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'query_pinecone' is not defined"
     ]
    }
   ],
   "source": [
    "results = query_pinecone(topic, NAMESPACE_KNOWLEDGE, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a625e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"System Prompt (Research Synthesis AI):\\nYou are an expert research synthesis AI. Synthesize the provided source texts into a concise, bullet-pointed summary relevant to the user's topic. Focus strictly on the facts provided in the sources. Do not add outside information.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompt import get_prompt\n",
    "get_prompt(role= \"system\" , \n",
    "           agent_type=\"research_synthesis_ai\",\n",
    "           topic = \"this this\" ,\n",
    "           sources=\"thsihs\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54724147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_researcher(mcp_message):\n",
    "\n",
    "    if not isinstance(mcp_message, dict):\n",
    "        raise TypeError(\"mcp_message must be a dictionary\")\n",
    "\n",
    "    # --- structure check ---\n",
    "    if \"content\" not in mcp_message or not isinstance(mcp_message[\"content\"], dict):\n",
    "        raise KeyError(\"mcp_message must contain a 'content' dictionary\")\n",
    "\n",
    "    if \"intent_query\" not in mcp_message[\"content\"]:\n",
    "        raise KeyError(\"mcp_message['content'] must contain 'intent_query'\")\n",
    "\n",
    "    if not isinstance(mcp_message[\"content\"][\"topic_query\"], str):\n",
    "        raise TypeError(\"'topic_query' must be a string\")\n",
    "\n",
    "    \n",
    "    print(\"Researcher Activated: Investigating topic ...\")\n",
    "    topic=  mcp_message['content']['topic_query']\n",
    "    source_texts= get_prompt(           role= \"system\" , \n",
    "                                         agent_type=\"research_synthesis_ai\", ) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
