{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81023720",
   "metadata": {},
   "source": [
    "### moving from jinja to python.py prompts \n",
    "i though i will use jinja for prompts here but forget that  jinja is not made for routing , my prompts \n",
    "here looks less like template and more like dynamic routing prompts \n",
    "\n",
    " i was using lots and lots of if else condition \n",
    "say for 20 agent , checking 20 if else condition make system slow so i am moving \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abefb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjwal/projects/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"    \n",
    "    Returns the prompt text for a given role and agent type.\n",
    "    Fills in any required variables provided as kwargs.\n",
    "    \n",
    "    Parameters:\n",
    "        role (str): 'system' or 'user'\n",
    "        agent_type (str): e.g., 'validator_agent', 'researcher_agent'\n",
    "        **kwargs: required variables for the prompt (if any)\n",
    "        \n",
    "    Returns:\n",
    "        str: Fully rendered prompt text\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from prompt import get_prompt\n",
    "from llm_clients import call_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2c4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name= 'genai-mas-mcp-01'\n",
    "NAMESPACE_KNOWLEDGE = \"knowledgeStore\"\n",
    "NAMESPACE_CONTEXT= \"ContextLibrary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fed6f",
   "metadata": {},
   "source": [
    "## create an MCP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b20a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_1\n",
      "Hello, this is a test message.\n",
      "{'priority': 'high', 'parents': ['writer-agent'], 'task_id': '062196b8-01bd-453f-8400-537c12776928'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "from pydantic import BaseModel , field_validator , Field \n",
    "from typing import Dict, Any , Union , TypedDict\n",
    "import uuid\n",
    "\n",
    "\n",
    "class ValidatorContext(BaseModel):\n",
    "    task: str\n",
    "    source_summary: str\n",
    "    draft_post: str\n",
    "\n",
    "\n",
    "\n",
    "class MCPMessage(BaseModel):\n",
    "    protocol_version: str = \"1.0\"\n",
    "    sender: str= Field(min_length=3)\n",
    "    content: Any\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "def create_mcp_message(sender: str ,  content: Any, metadata=None) -> MCPMessage:\n",
    "    \"\"\"Create a message in MCP format.\"\"\"\n",
    "\n",
    "    \n",
    "    if not isinstance(content, (str, dict, ValidatorContext)):\n",
    "        raise TypeError(\n",
    "            f\"content must be str, dict, or ValidatorContext; got {type(content).__name__}\"\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "    metadata = metadata or {} \n",
    "    metadata.setdefault(\"task_id\", str(uuid.uuid4()))\n",
    "    metadata.setdefault(\"parents\",[])\n",
    "\n",
    "    return MCPMessage(\n",
    "        sender=sender,\n",
    "        content=content,\n",
    "        metadata=metadata   \n",
    "    )\n",
    "\n",
    "mcp_answer = create_mcp_message(\"agent_1\", \"Hello, this is a test message.\", {\"priority\": \"high\" , \"parents\": [\"writer-agent\"]})\n",
    "print(mcp_answer.sender)\n",
    "print(mcp_answer.content)\n",
    "print(mcp_answer.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d30973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MCP Message (Sender: agent_1) ---\n",
      "Content: Hello, this is a test message.\n",
      "Metadata Keys: ['priority', 'parents', 'task_id']\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from helper import display_mcp \n",
    "display_mcp(mcp_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a8b57",
   "metadata": {},
   "source": [
    "####  not using any fallback logics or anything or simplicity \n",
    "#### i found i  will only use those if topic specific or  in end to end projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6cf0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc8274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_context_librarian(mcp_message:MCPMessage):\n",
    "    \"\"\"\n",
    "        Retrieves the appropriate Semantic Blueprint from the Context Library.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not INDEX :\n",
    "        raise(\"this except Pine cone index \")\n",
    "\n",
    "\n",
    "    if \"intent_query\" not in mcp_message.content:\n",
    "        raise KeyError(\"mcp_message['content'] must contain 'intent_query'\")\n",
    "    \n",
    "    print(\"\\\\n[Librarian] Activated. Analyzing intent...\")\n",
    "    requested_intent = mcp_message.content['intent_query']\n",
    "    results = query_pinecone(index= INDEX, query_text=requested_intent, namespace= NAMESPACE_CONTEXT, top_k=1)\n",
    "    if results:\n",
    "        match = results[0]\n",
    "        print(f\"[Librarian] Found blueprint '{match['id']}' (Score:{match['score']:.2f})\")\n",
    "        blueprint_json = match['metadata']['blueprint_json']\n",
    "        content = {\"blueprint\": blueprint_json}\n",
    "\n",
    "    else:\n",
    "        print(\"[Librarian] No specific blueprint found. Returning default.\")\n",
    "        content = {\"blueprint\": json.dumps({\"instruction\": \"Generate the content neutrally.\"})}\n",
    "    return create_mcp_message(\"Librarian\", content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef9009",
   "metadata": {},
   "source": [
    "## research agent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753121c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pine cone query \n",
    "from helper import query_pinecone \n",
    "## takes  query_text , namespaces and tok k (optional, because defult is 1)\n",
    "## and return index query ... response['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24723db",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'genai-mas-mcp-01'\n",
    "NAMESPACE_KNOWLEDGE = \"knowledgeStore\"\n",
    "NAMESPACE_CONTEXT = \"ContextLibrary\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0766b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_or_create_index\n",
    "from llm_clients import pine_cone_client\n",
    "\n",
    "index = get_or_create_index(\n",
    "    pc=pine_cone_client,\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding_dim=384,\n",
    "    namespaces_to_clear=None  # important: keep existing vectors\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49f7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define test query\n",
    "query_text = \"create a suspense narrator story\"\n",
    "\n",
    "# 3. Query CONTEXT namespace (semantic blueprints live here)\n",
    "context_results = query_pinecone(\n",
    "    index=index,\n",
    "    query_text=query_text,\n",
    "    namespace=NAMESPACE_KNOWLEDGE,\n",
    "    top_k=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7720707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'knowledge_chunk_1',\n",
       "  'metadata': {'text': 'nuclear power, demonstrating that solar energy can '\n",
       "                       'support missions even at great distances from the Sun.  '\n",
       "                       'Mars exploration represents another major focus of '\n",
       "                       'modern space science. Robotic rovers act as mobile '\n",
       "                       'laboratories, analyzing soil, rocks, and atmospheric '\n",
       "                       'conditions. NASA’s Perseverance rover is specifically '\n",
       "                       'designed to investigate whether Mars ever supported '\n",
       "                       'microbial life, while also testing technologies for '\n",
       "                       'future human missions. It carried the Ingenuity '\n",
       "                       'helicopter, which achieved the first powered flight on '\n",
       "                       'another planet, proving that aerial exploration is '\n",
       "                       'possible beyond Earth.  Together, these missions show '\n",
       "                       'how space exploration has evolved from political '\n",
       "                       'competition into a long-term scientific and '\n",
       "                       'technological endeavor aimed at expanding human '\n",
       "                       'knowledge and enabling future interplanetary travel.'},\n",
       "  'score': 0.00999168586,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c738d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nuclear power, demonstrating that solar energy can support missions even at great distances from the Sun.  Mars exploration represents another major focus of modern space science. Robotic rovers act as mobile laboratories, analyzing soil, rocks, and atmospheric conditions. NASA’s Perseverance rover is specifically designed to investigate whether Mars ever supported microbial life, while also testing technologies for future human missions. It carried the Ingenuity helicopter, which achieved the first powered flight on another planet, proving that aerial exploration is possible beyond Earth.  Together, these missions show how space exploration has evolved from political competition into a long-term scientific and technological endeavor aimed at expanding human knowledge and enabling future interplanetary travel.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text['metadata']['text'] for text in context_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a25286",
   "metadata": {},
   "source": [
    "## agent research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "782474c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_clients import cohere_chat_client\n",
    "from prompt import get_prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57681b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function helper.query_pinecone(index, query_text: str, namespace: str, top_k: int = 1)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d1282a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_researcher(mcp_message:MCPMessage):\n",
    "    \n",
    "    topic= mcp_message.content['topic_query']\n",
    "    results= query_pinecone(index= INDEX , query_text=topic, namespace =NAMESPACE_KNOWLEDGE, top_k=3)\n",
    "    if not results: \n",
    "        print(\"[researcher] no Relevant information found\")\n",
    "        return create_mcp_message(\"Researcher\", {\"facts\" : \"No data found\"})\n",
    "    \n",
    "    source_texts = [match['metadata']['text'] for match in results]\n",
    "    system_prompt= get_prompt(role=\"system\", agent_type=\"research_synthesis_ai\")\n",
    "    \n",
    "    user_prompt=  get_prompt(role=\"user\", agent_type=\"research_synthesis_ai\",topic= topic , sources= source_texts )\n",
    "    \n",
    "    findings= call_llm(system_prompt, user_prompt)\n",
    "    \n",
    "    return create_mcp_message(\"Researcher\" , {\"facts\": findings})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3673764",
   "metadata": {},
   "source": [
    "## Writer agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3d0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_writer(mcp_message):\n",
    "    \n",
    "    print(\"\\\\n[Writer] Activated. Applying blueprint to facts...\")\n",
    "    facts= mcp_message.content['facts']\n",
    "    blueprint_json_string= mcp_message.content['blueprint']\n",
    "    \n",
    "    system_prompt= get_prompt(role='system' , agent_type=\"writer_blueprint\" , blueprint_json_string = blueprint_json_string)\n",
    "    user_prompt= get_prompt(role=\"user\",agent_type= \"research_facts\", facts= facts  )\n",
    "    \n",
    "    final_output= call_llm(system_prompt, user_prompt)\n",
    "    return create_mcp_message(\"Writer\", {\"output\": final_output})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56704326",
   "metadata": {},
   "source": [
    "# final (building the orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e1fddd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an expert goal analyst.\\nAnalyze the user's high-level goal and extract two components:\\n1. 'intent_query': A descriptive phrase summarizing the desired style, tone, or format, optimized for searching a context library (e.g., 'suspenseful narrative blueprint', 'objective technical explanation structure').\\n2. 'topic_query': A concise phrase summarizing the factual subject matter required (e.g., 'Juno mission objectives and power', 'Apollo 11 landing details').\\nRespond ONLY with a JSON object containing these two keys.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompt import get_prompt \n",
    "system_prompt= get_prompt(role='system' , agent_type=\"goal_analyst\" )\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65348e",
   "metadata": {},
   "source": [
    "## Goal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb46e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_clients import call_llm\n",
    "analysis_system_prompt = \"\"\"You are an expert goal analyst.\n",
    "                            Analyze the\n",
    "                            user's high-level goal and extract two components:\n",
    "                            1. 'intent_query': A descriptive phrase summarizing the desired style, tone,\n",
    "                            or format, optimized for searching a context library (e.g., \"suspenseful narrative\n",
    "                            blueprint\", \"objective technical explanation structure\").\n",
    "                            2. 'topic_query': A concise phrase summarizing the factual subject matter\n",
    "                            required (e.g., \"Juno mission objectives and power\", \"Apollo 11 landing details\").\n",
    "                            Respond ONLY with a JSON object containing these two keys.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90cab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearcherOutput(intent_query='informal greeting style', topic_query='basic conversational phrases')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer= call_llm(system_prompt = analysis_system_prompt ,user_content=  \"hellow\", structured=True)\n",
    "answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf1b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_query': 'informal greeting style',\n",
       " 'topic_query': 'basic conversational phrases'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d2ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_clients import pine_cone_client \n",
    "index_name= 'genai-mas-mcp-01'\n",
    "NAMESPACE_KNOWLEDGE = \"knowledgeStore\"\n",
    "NAMESPACE_CONTEXT= \"ContextLibrary\"\n",
    "\n",
    "INDEX= get_or_create_index(pc = pine_cone_client , index_name= index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e831dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(hight_level_goal):\n",
    "    \"\"\" Manages the workflow of the context Aware MAS \"\"\" \n",
    "    \n",
    "    print(f\"high level goal :  {hight_level_goal}\")\n",
    "    system_prompt= get_prompt(role='system' , agent_type=\"goal_analyst\" )\n",
    "    \n",
    "    analysis_results= call_llm(system_prompt, hight_level_goal, structured=True)\n",
    "    \n",
    "    try: \n",
    "\n",
    "        intent_query= analysis_results.intent_query \n",
    "        topic_query= analysis_results.topic_query\n",
    "    except   : \n",
    "        return  \"error occours while trying to fetch intent , topic query\"\n",
    "    \n",
    "    # Agent coordination \n",
    "    mcp_to_librarian= create_mcp_message(\n",
    "        sender= \"Orchestration\",\n",
    "        content= {\"intent_query\" : intent_query} \n",
    "    )\n",
    "    \n",
    "    mcp_from_librarian= agent_context_librarian(mcp_to_librarian)\n",
    "    \n",
    "    ## display mcp \n",
    "    display_mcp(mcp_from_librarian ,\"Librarian -> Orchestrator\")\n",
    "    \n",
    "    context_blueprint = mcp_from_librarian.content.get('blueprint')\n",
    "    \n",
    "    if not context_blueprint:\n",
    "        raise ValueError(\"No blueprint found in Librarian's content\")\n",
    "\n",
    "    ## step 2 \n",
    "    mcp_to_researcher = create_mcp_message( sender=\"Orchestrator\", content={\"topic_query\": topic_query})\n",
    "    mcp_from_researcher=agent_researcher(mcp_to_researcher)\n",
    "    display_mcp(mcp_from_researcher)\n",
    "    \n",
    "    research_finding= mcp_from_researcher.content.get('facts')\n",
    "    if not research_finding :\n",
    "        raise ValueError(\"no research finding \")\n",
    "    \n",
    "    ## generate final output , step 3\n",
    "    writer_task = {\n",
    "                        \"blueprint\": context_blueprint,\n",
    "                        \"facts\": research_finding\n",
    "                        }\n",
    "    \n",
    "    mcp_to_writer = create_mcp_message(\n",
    "                                        sender=\"Orchestrator\",\n",
    "                                        content=writer_task\n",
    "                                        )\n",
    "    \n",
    "                                            \n",
    "    mcp_from_writer = agent_writer(mcp_to_writer)\n",
    "    display_mcp(mcp_from_writer, \"Writer -> Orchestrator\")\n",
    "    \n",
    "    \n",
    "    final_result = mcp_from_writer.content.get('output')\n",
    "    \n",
    "    return final_result \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ac97e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high level goal :  Explain space exploration in a suspenseful story\n",
      "\\n[Librarian] Activated. Analyzing intent...\n",
      "[Librarian] Found blueprint 'blueprint_suspense_narrative' (Score:0.39)\n",
      "\n",
      "--- Librarian -> Orchestrator (Sender: Librarian) ---\n",
      "Content Keys: ['blueprint']\n",
      "Metadata Keys: ['task_id', 'parents']\n",
      "--------------------------------------------------\n",
      "\n",
      "--- MCP Message (Sender: Researcher) ---\n",
      "Content Keys: ['facts']\n",
      "Metadata Keys: ['task_id', 'parents']\n",
      "------------------------------------\n",
      "\\n[Writer] Activated. Applying blueprint to facts...\n",
      "\n",
      "--- Writer -> Orchestrator (Sender: Writer) ---\n",
      "Content Keys: ['output']\n",
      "Metadata Keys: ['task_id', 'parents']\n",
      "-----------------------------------------------\n",
      "**Shadows in the Void**  \n",
      "\n",
      "The Agent stands in the dim glow of the control room. Screens flicker with data from distant worlds. The hum of machines fills the air, a steady rhythm in the silence. Outside, the vastness of space presses against the station’s walls, a darkness broken only by the faint glimmer of stars.  \n",
      "\n",
      "The Source of Threat lurks unseen. It’s not a creature or a force, but a question: *What lies beyond?* The Agent’s fingers hover over the console, tracing the path of the Ingenuity Helicopter. Its blades cut through Martian air, a whisper of triumph. But the whisper fades. The feed lags. Shadows stretch across the red terrain, longer than they should be.  \n",
      "\n",
      "The Agent’s breath catches. A glitch? Or something else? The Juno spacecraft orbits Jupiter, its solar panels gleaming like fragile wings. But the data stream stutters. Numbers flicker. The Agent leans closer, squinting at the screen. A shadow passes over the feed, too fast, too dark.  \n",
      "\n",
      "The Perseverance rover drills into Martian soil. Its cameras capture rock, dust, and—something else. A glint. A shape. The Agent’s heart quickens. The feed cuts. Static hisses. The Agent’s hand trembles as they reach for the comms.  \n",
      "\n",
      "The station creaks. A sound, faint but unmistakable, echoes through the halls. Not mechanical. Not human. The Agent freezes. The Source of Threat is closer than they thought.  \n",
      "\n",
      "The Agent’s mind races. Milestones, achievements—they mean nothing now. The void is vast. The unknown is deeper. And the shadows are moving.\n"
     ]
    }
   ],
   "source": [
    "result = orchestrator(\"Explain space exploration in a suspenseful story\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e2dc1",
   "metadata": {},
   "source": [
    "## THE END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
